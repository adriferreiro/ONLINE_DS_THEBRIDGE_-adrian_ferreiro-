{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import json\n",
    "from openai import ChatCompletion, Completion, OpenAI\n",
    "from pypdf import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\edici\\Nigmae\\Sherezade\\Brain\\Building_Sharzade\\Labs\\aiclose.oai\",\"r\") as f:\n",
    "    apikey = json.load(f)[\"token\"]\n",
    "openai.api_key = apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-3.5-turbo-0125\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consulta(rol,prompt):\n",
    "    respuesta =  client.chat.completions.create(\n",
    "                model= MODEL,\n",
    "                messages = [\n",
    "                    {\"role\": \"system\", \"content\": rol},\n",
    "                    {\"role\": \"user\",\"content\": prompt}\n",
    "                ],\n",
    "                temperature = 0,\n",
    "    )\n",
    "    return respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key= apikey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respuestas = []\n",
    "pages_to_include = 3\n",
    "for fichero in os.listdir(\"data\"):\n",
    "    print(fichero)\n",
    "    reader = PdfReader(\"data/\" + fichero)\n",
    "    number_of_pages = len(reader.pages)\n",
    "    text = []\n",
    "    for page in reader.pages[0:pages_to_include]:\n",
    "        text.append(page.extract_text())\n",
    "    print(number_of_pages)\n",
    "    rol = \"Eres un experto en modelos LLM y en inteligencia artificial\"\n",
    "    prompt = f'''Hazme un resumen del texto que te incluyo entre triples comillas \"\"\"{text}\"\"\". Por favor NO quiero el resumen en formato texto, lo quiero en markdown con las palabras más importantes en negrita'''\n",
    "    respuestas.append(consulta(rol, prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respuesta = respuestas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(respuesta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(respuesta.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(respuestas[1].choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referencias:\n",
    "\n",
    "[La librería para trabajar con los LLM programáticamente: LangChain](https://www.langchain.com/langchain)  \n",
    "[Para saber más: Andrew Ng y deeplearning.ai](https://www.deeplearning.ai/short-courses/)  \n",
    "[Lo que está de moda: RAG (Retrieval Augmented Generation) y alguna cosilla más](https://datos.gob.es/en/blog/rag-retrieval-augmented-generation-key-unlocks-door-precision-language-models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Curso_Online_DATA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
